# Profiling Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: logs, metrics, traces   |
| Distributions | [] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fprofiling%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fprofiling) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fprofiling%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fprofiling) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector-contrib/graph/main/badge.svg?component=processor_profiling)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/tree/main/?components%5B0%5D=processor_profiling&displayType=list) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@alexcams](https://www.github.com/alexcams) |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
<!-- end autogenerated section -->

The Profiling Processor measures the performance characteristics of the next processor in the pipeline. It collects metrics about payload sizes, error rates, success rates, and throughput for the configured processor without requiring any modifications to that processor's code.

This processor acts as a transparent wrapper around the next processor in the pipeline, intercepting calls to collect performance metrics while passing telemetry data through unchanged.

## Configuration

```yaml
processors:
  profiling:
    # Label identifies the next processor being measured (required)
    label: "transform"
    
    # Metrics configuration - enable/disable specific metrics (at least one should be enabled)
    metrics:
      payload_size: true    # Distribution of payload sizes in bytes
      error_count: true     # Count of errors by type (permanent/transient)
      success_rate: true    # Success rate as a percentage
      throughput: true      # Throughput in kilobytes per second
      enable_logging: true  # Log metric values in addition to exporting them


pipelines:
  logs:
    # profiling must be placed immediately before transform to measure it
    processors: [batch, profiling, transform] 
```

### Configuration Fields

- `label` (required): A string that identifies the next processor being measured in the pipeline. This label is included as an attribute in all exported metrics, allowing you to distinguish between different profiling processor instances when monitoring multiple pipeline segments.

- `metrics` (optional): Configuration for which metrics to collect and export. At least one metric must be enabled.
  - `payload_size` (default: `true`): Tracks the distribution of payload sizes in bytes using a histogram. Measures the actual protobuf-encoded size of the telemetry data.
  - `error_count` (default: `false`): Counts errors by type (`permanent` or `transient`) returned from the downstream processor.
  - `success_rate` (default: `false`): Calculates the success rate as a percentage based on successful vs failed executions.
  - `throughput` (default: `false`): Measures throughput in kilobytes per second, calculated internally every second.
  - `enable_logging` (default: `false`): If enabled, logs metric values in addition to exporting them to the configured telemetry backend.

## Metrics

The profiling processor exports the following metrics (all are prefixed with `processor_profiling_`):

### payload_size

- **Type**: Exponential Histogram
- **Unit**: Bytes (By)
- **Description**: Distribution of payload sizes in bytes for telemetry data passing through the processor
- **Attributes**: `label`

### error_count

- **Type**: Counter (monotonic)
- **Unit**: Count (1)
- **Description**: Total number of errors encountered in the next processor
- **Attributes**: `label`, `error_type` (`permanent` or `transient`)

### success_rate

- **Type**: Gauge
- **Unit**: Percent (%)
- **Description**: Success rate of the next processor as a percentage
- **Attributes**: `label`

### throughput

- **Type**: Gauge
- **Unit**: Kilobytes per second (kB/s)
- **Description**: Throughput of the next processor, calculated every second
- **Attributes**: `label`

## Examples

### Basic Usage

Profile the performance of the transform processor (the profiling processor must be placed immediately before the processor you want to measure):

```yaml
receivers:
  otlp:
    protocols:
      grpc:

processors:
  profiling:
    label: "transform"
    metrics:
      payload_size: true

  transform:
    log_statements:
      - set(severity_text, "INFO") where severity_text == "info"

exporters:
  debug:

service:
  telemetry:
    metrics:
      address: ":8888"
  pipelines:
    logs:
      receivers: [otlp]
      processors: [profiling, transform]
      exporters: [debug]
```

### Monitoring Multiple Pipeline Segments

Use multiple profiling processors to measure different parts of your pipeline:

```yaml
receivers:
  otlp:
    protocols:
      grpc:

processors:
  profiling/batch:
    label: "batch"
    metrics:
      payload_size: true
      throughput: true
  
  batch:
    timeout: 200ms
    send_batch_size: 100
  
  profiling/transform:
    label: "transform"
    metrics:
      payload_size: true
      error_count: true
      success_rate: true
  
  transform:
    log_statements:
      - set(severity_text, "INFO") where severity_text == "info"

exporters:
  otlp:
    endpoint: backend:4317

service:
  telemetry:
    metrics:
      address: ":8888"
  pipelines:
    logs:
      receivers: [otlp]
      processors: [profiling/batch, batch, profiling/transform, transform]
      exporters: [otlp]
```

### Minimal Configuration

Monitor single metric with logging:

```yaml
processors:
  profiling:
    label: "error_monitor"
    metrics:
      error_count: true
      enable_logging: true
```

## Use Cases

- **Performance Monitoring**: Track payload sizes and throughput to identify performance bottlenecks in your pipeline
- **Error Analysis**: Monitor error rates and types to detect issues with downstream processors
- **Capacity Planning**: Analyze payload size distributions to plan resource allocation
- **Pipeline Optimization**: Compare metrics before and after pipeline changes to measure improvements
- **SLA Monitoring**: Track success rates to ensure pipeline reliability meets service level objectives

## Notes

- The profiling processor must be placed **immediately before** the processor you want to measure in the pipeline configuration
- It only measures the **next processor** in the pipeline - if you want to measure multiple processors, use multiple profiling processor instances, each one can have a different configuration
- Throughput is calculated internally every second using a background goroutine and if log is enabled, it will be logged separately every seccond.
- At least one metric (excluding `enable_logging`) must be enabled for the processor to function
- The processor requires a valid telemetry configuration or logging enabled; it returns an error if metrics are not properly configured because it will be useless in that case
